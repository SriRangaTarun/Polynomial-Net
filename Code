import numpy as np

X = []                                                                       # X and Y are lists containing the values of the independent and 
Y = []                                                                       # dependent variables respectively

num = 30

for i in range(-num, num):
    X.append(i)
    
E = []

for i in range(-num, num):
    E.append(20000*np.random.normal())                                      # random normal error term

n_samples = 2*num
Y = np.multiply(X, np.multiply(X, np.multiply(X, X))) - np.multiply(X, X) + E                

if min(X) < 0:          
    X = np.array(X) - [min(np.array(X))]*len(X)
    
    
if max(Y) < 0:
    Y = [-Y[i] for i in range(0, len(Y))]
    
if (Y[0] > Y[n_samples // 2] and Y[n_samples // 2] > Y[n_samples - 1]) or (Y[0] < Y[n_samples // 2] and Y[n_samples - 1] < Y[n_samples // 2]):
    Y = [-Y[i] for i in range(0, len(Y))]
    

# All the above three if cases manipulate the input data such that the model can find the degree more convenietly (preprocessing data)
    
X = np.reshape(X, (len(X), 1))
Y = np.reshape(Y, (len(Y), 1))
    
***********************************************************************************************************************************************

def buildModelAndPredictDegree(X, Y):                               # Predicts degree of polynomial relationship between X and Y

    import keras
    import tensorflow as tf
    from math import isnan
    from keras import backend as K
    
    sess = tf.InteractiveSession()
    K.set_session(sess)
    
    from keras.models import Model
    from keras.layers import Input, Dense, Lambda, multiply

    n = tf.Variable(1.0)
    x = Input(shape=(1,))

    dense_a = Dense(2)(x)
    dense_b = Dense(1)(dense_a)
    powered_dense1 = Lambda(lambda x: tf.abs(x)**(n/4.0))((dense_b))
    model1 = Model(x, powered_dense1)
    model1.layers[-1].trainable_weights.extend([n])

    dense_c = Dense(2)(x)
    dense_d = Dense(1)(dense_c)
    powered_dense2 = Lambda(lambda x: tf.abs(x)**(n/4.0))((dense_d))
    model2 = Model(x, powered_dense2)
    model2.layers[-1].trainable_weights.extend([n])

    dense_e = Dense(2)(x)                                             # "n" is the parameter representing the degree
    dense_f = Dense(1)(dense_e)
    powered_dense3 = Lambda(lambda x: tf.abs(x)**(n/4.0))((dense_f))
    model3 = Model(x, powered_dense3)
    model3.layers[-1].trainable_weights.extend([n])

    dense_g = Dense(2)(x)
    dense_h = Dense(1)(dense_g)
    powered_dense4 = Lambda(lambda x: tf.abs(x)**(n/4.0))((dense_h))
    model4 = Model(x, powered_dense4)
    model4.layers[-1].trainable_weights.extend([n])

    model = Model(x, multiply([model1.output, model2.output, model3.output, model4.output]))

    from keras.optimizers import RMSprop
    model.compile(loss='mae', optimizer=RMSprop(lr=0.01))
    
    tf.global_variables_initializer().run()
    
    for _ in range(0, 5000):                                         
        model.fit(X, Y, epochs=1, verbose=0)              
        
        if isnan(sess.run(n)):                                       # handle numerical instabilities by rebuilding and retraining model when n = "nan"
           buildModelAndPredictDegree(X, Y)
        
    return np.int32(np.round(sess.run(n)))                           # return rounded degree  


***********************************************************************************************************************************************

print(buildModelAndPredictDegree(X, Y))


